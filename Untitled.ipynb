{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5def45-60ff-44c2-9095-33cb151ee9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063688f-e7c1-41e5-9d88-fc0cfca2689a",
   "metadata": {},
   "source": [
    "# Garments Dataset\n",
    "\n",
    "Important characteristics of the clothing manufacturing process are included in this dataset, along with the \n",
    "productivity of the workers, which was manually gathered and confirmed by the \n",
    "industry insiders. It contains features that can serve as indicators of productivity over a certain period of time. The data was extracted by Rahim et al. (2021) using advanced data mining techniques such as the tree ensemble model and gradient boosted tree model which happened to be the best performing candidates in a pool of other gathering methods. A tree ensemble is a machine learning model which makes predictions by utilizing several decision trees as opposed to just one. On the other hand, a Gradient Boosted Tree model is an ensemble learning technique wherein new models are built to predict the errors or residuals of previous models, which are then combined to produce the final prediction. It also makes use of the gradient descent algorithm to minimize the loss when adding new models.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b4a7f5-0a7c-407e-8350-397b337ecd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/garments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7629bfd-4c65-41d4-bf9c-02681f778517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date   quarter  department       day  team  targeted_productivity  \\\n",
      "0  1/1/2015  Quarter1      sweing  Thursday     8                   0.80   \n",
      "1  1/1/2015  Quarter1  finishing   Thursday     1                   0.75   \n",
      "2  1/1/2015  Quarter1      sweing  Thursday    11                   0.80   \n",
      "3  1/1/2015  Quarter1      sweing  Thursday    12                   0.80   \n",
      "4  1/1/2015  Quarter1      sweing  Thursday     6                   0.80   \n",
      "\n",
      "     smv     wip  over_time  incentive  idle_time  idle_men  \\\n",
      "0  26.16  1108.0       7080         98        0.0         0   \n",
      "1   3.94     NaN        960          0        0.0         0   \n",
      "2  11.41   968.0       3660         50        0.0         0   \n",
      "3  11.41   968.0       3660         50        0.0         0   \n",
      "4  25.90  1170.0       1920         50        0.0         0   \n",
      "\n",
      "   no_of_style_change  no_of_workers  actual_productivity  \n",
      "0                   0           59.0             0.940725  \n",
      "1                   0            8.0             0.886500  \n",
      "2                   0           30.5             0.800570  \n",
      "3                   0           30.5             0.800570  \n",
      "4                   0           56.0             0.800382  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0a041c6-e8e3-499b-8a38-21c04661cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thursday' 'Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday']\n"
     ]
    }
   ],
   "source": [
    "print(df['day'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0496ca8-b3b6-47ae-8be2-ab3ab286ec00",
   "metadata": {},
   "source": [
    "The dataset consists of 1197 rows (entires) and 15 columns (features).\n",
    "The 15 features are:\n",
    "- date\n",
    ">  Date in MM-DD-YYYY\n",
    "- quarter\n",
    "> A portion of the month. A month was divided into four quarters.\n",
    "- department\n",
    "> Department associated with the instance.\n",
    "- day\n",
    "> Day of the week\n",
    "- team\n",
    "> Team number associated with the instance.\n",
    "- targeted_productivity\n",
    "> Targeted productivity set by the authority for each team for each \r\n",
    "da\n",
    "- smv\n",
    "> Standard Minute Value; the allocated time for a task\n",
    "- wip\n",
    "> Work in progress. Includes the number of unfinished items for products.\n",
    "- over_time\n",
    "> Represents the amount of overtime by each team in minutes.\n",
    "- incentive\n",
    "> Represents the amount of financial incentive that enables or motivates a \r\n",
    "particular course of action\n",
    "- idle_time\n",
    "> The amount of time when the production was interrupted due to several \r\n",
    "reasons\n",
    "- idle_men\n",
    "> The number of workers who were idle due to production interruption.\n",
    "- no_of_style_change\n",
    "> Number of changes in the style of a particular product\n",
    "- no_of_workers\n",
    "> Number of workers in each team\n",
    "- actual_productivity\n",
    "> The actual % of productivity that was delivered by the workers. It \n",
    "ranges from 0-1om 0-1.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63221eae-397f-4624-b806-6cc403b2742b",
   "metadata": {},
   "source": [
    "## Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e4602-dc3c-4777-b76f-59805758aecb",
   "metadata": {},
   "source": [
    "Before we do any machine learning, we need to prepare our data and ensure that it is as clean as possible to improve our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62d9823-fe07-4f6f-9bf9-dddb0dced0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c9f52c-08e4-481e-9fa5-1d753a836a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_num = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fb99a6c-8e87-4d55-babd-83b4c095bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       0\n",
      "quarter                    0\n",
      "department                 0\n",
      "day                        0\n",
      "team                       0\n",
      "targeted_productivity      0\n",
      "smv                        0\n",
      "wip                      506\n",
      "over_time                  0\n",
      "incentive                  0\n",
      "idle_time                  0\n",
      "idle_men                   0\n",
      "no_of_style_change         0\n",
      "no_of_workers              0\n",
      "actual_productivity        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count = df.isnull().sum()\n",
    "print(null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4cd414-c339-4075-bc9a-9f872c63ab81",
   "metadata": {},
   "source": [
    "As you can see from the display above, most columns do not contain a null value, with the only exception being the column **wip**. To counter this, we will be using a SimpleImputer from the sklearn library with a mean strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0c0dbaf-58c4-4376-b2c5-5b17ae766210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wip'] = imputer_num.fit_transform(df[['wip']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0b5833b-edfb-45b1-9269-7de8cc01bb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                     0\n",
      "quarter                  0\n",
      "department               0\n",
      "day                      0\n",
      "team                     0\n",
      "targeted_productivity    0\n",
      "smv                      0\n",
      "wip                      0\n",
      "over_time                0\n",
      "incentive                0\n",
      "idle_time                0\n",
      "idle_men                 0\n",
      "no_of_style_change       0\n",
      "no_of_workers            0\n",
      "actual_productivity      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count = df.isnull().sum()\n",
    "print(null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce781c62-612b-4000-846a-d07a1dd08f3f",
   "metadata": {},
   "source": [
    "After using the SimpleImputer, there are now 0 null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b818806-016e-4f2b-b7c1-26fb3298f13d",
   "metadata": {},
   "source": [
    "Next, let's look for misrepresented data or noise that could be a result of typos, input error, data leakage, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c49f3be-76b5-435a-88a8-4240d7d296e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sweing' 'finishing ' 'finishing']\n"
     ]
    }
   ],
   "source": [
    "print(df['department'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc5816-60ce-4773-8413-5f17b495dc72",
   "metadata": {},
   "source": [
    "In the **department** column, there are two different column values for **finishing**, one suffixed with an empty space and one without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4debf95-2d5b-4744-8638-7a53af01a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['department'] = df['department'].replace('finishing ', 'finishing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed76b037-4a62-4000-af4c-78fd1267e848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sweing' 'finishing']\n"
     ]
    }
   ],
   "source": [
    "print(df['department'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75819e77-dc17-4828-86fe-d53f71b88428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now looking at normalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
